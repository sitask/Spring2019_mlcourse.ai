{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
    "Authors: [Yury Kashnitskiy](https://yorko.github.io) (@yorko), Yury Isakov. Edited by Anna Tarelina (@feuerengel), and Kolchenko Sergey (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment #2. Spring 2019\n",
    "## <center>  Competition 1. User Identification with Logistic Regression <br>(beating baselines in the \"Alice\" competition)\n",
    "\n",
    "    \n",
    "Today we are going to practice working with sparse matrices, training Logistic Regression models, and doing feature engineering. We will reproduce a couple of baselines in the  Kaggle Inclass competition [\"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) (a.k.a. \"Alice\"). More credits will be given for beating stronger baselines. \n",
    "\n",
    "Prior to working on the assignment, you'd better check out the corresponding course material:\n",
    " 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) (basics of machine learning are covered here)\n",
    " 2. Linear classification and regression in 5 parts: \n",
    "    - [ordinary least squares](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols)\n",
    "    - [linear classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification)\n",
    "    - [regularization](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-3-regularization)\n",
    "    - [logistic regression: pros and cons](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit)\n",
    "    - [validation](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-5-validation)\n",
    " 3. You can also practice with demo assignments, which are simpler and already shared with solutions: \n",
    "    - \" Sarcasm detection with logistic regression\": [assignment](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit) + [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution)\n",
    "    - \"Linear regression as optimization\": [assignment](https://www.kaggle.com/kashnitsky/a4-demo-linear-regression-as-optimization/edit) (solution cannot be officially shared)\n",
    "    - \"Exploring OLS, Lasso and Random Forest in a regression task\": [assignment](https://www.kaggle.com/kashnitsky/a6-demo-linear-models-and-rf-for-regression) + [solution](https://www.kaggle.com/kashnitsky/a6-demo-regression-solution)\n",
    " 4. Alice baseline with logistic regression and \"bag of sites\", [Kernel](https://www.kaggle.com/kashnitsky/alice-logistic-regression-baseline)\n",
    " 5. Correct time-aware cross-validation scheme, more features, and hyperparameter optimization, [Kernel](https://www.kaggle.com/kashnitsky/correct-time-aware-cross-validation-scheme)\n",
    " 6. Other [Kernels](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/kernels?sortBy=voteCount&group=everyone&pageSize=20&competitionId=7173) in this competition. You can share yours as well, but not high-performing ones (Public LB MAE shall be < 0.95). Please don't spoil the competitive spirit. \n",
    " 7. If that's still not enough, watch two videos on logistic regression: [mlcourse.ai/video](https://mlcourse.ai/video)\n",
    "\n",
    "**Your task:**\n",
    " 1. \"Follow me\". Complete the missing code and submit your answers via [the google form](https://docs.google.com/forms/d/15PVw9CYlX6QnxRHKIDS161kGAq3v7iiO15W3qKTePEY). Use **the same email** as in A1 (for newcomers: remember your email and use it for all forms during the course). 12 credits max. for this part\n",
    " 2. \"Freeride\". Come up with good features to beat the baselines \"A2 baseline (10 credits)\" and \"A2 strong baseline (20 credits)\". As names suggest, you'll get 10 more credits for beating the first one, and 10 more (20 in total) for beating the second one. You need to name your [team](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/team) (out of 1 person) in full accordance with the [course rating](https://docs.google.com/spreadsheets/d/1LAy1eK8vIONzIWgcCEaVmhKPSj579zK5lrECf_tQT60/edit?usp=sharing) (for newcomers: you need to name your team with your real full name). You can think of it as a part of the assignment.\n",
    " 3. If you've beaten \"A2 baseline (10 credits)\" or performed better, you need to upload your solution as described in [course roadmap](https://mlcourse.ai/roadmap) (\"Kaggle Inclass Competition Alice\" -> Rules). For all baselines that you see on Public Leaderboard, it's OK to beat them on Public LB as well. But 10 winners will be defined according to the private LB, which will be revealed by @yorko on March 11. \n",
    " \n",
    " ### <center> Deadline for A2: 2019 March 10, 20:59 GMT (London time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...                 time6  site7  \\\n",
       "session_id                      ...                                \n",
       "21669                      NaT  ...                   NaT    NaN   \n",
       "54843                      NaT  ...                   NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training and test data sets, change paths if needed\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df = pd.read_csv('data/train_sessions.csv',\n",
    "                       index_col='session_id', parse_dates=times)\n",
    "test_df = pd.read_csv('data/test_sessions.csv',\n",
    "                      index_col='session_id', parse_dates=times)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Look at the first rows of the training set\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us look at the timestamps and try to characterize sessions as timeframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change site1, ..., site10 columns type to integer and fill NA-values with zeros\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype(np.uint16)\n",
    "test_df[sites] = test_df[sites].fillna(0).astype(np.uint16)\n",
    "\n",
    "# Load websites dictionary\n",
    "with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable\n",
    "y_train = train_df['target']\n",
    "\n",
    "orig_train = train_df\n",
    "\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with indices of visited websites in session\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us remove the www. in url and regenerate our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_dict(sites_dict):\n",
    "    '''\n",
    "    Gets a key-value dictionary. \n",
    "    Returns the dictionary by swapping the key and value.\n",
    "    '''\n",
    "    code_sites_dict = {}\n",
    "    sites = list(sites_dict.items())\n",
    "    for site in sites:\n",
    "        code_sites_dict[site[1]] = site[0]\n",
    "    return code_sites_dict\n",
    "\n",
    "def get_sites_dict_(data):\n",
    "    '''\n",
    "    Gets dataframe with site names (10 columns) as input.\n",
    "    Returns a dictionary of sites ordered by frequency.\n",
    "    '''\n",
    "    m, n = data.shape #num of rows and columns\n",
    "    data = pd.DataFrame(data.values.reshape(m*n, 1), columns=['site']) #transform to 1 column\n",
    "    freq = data.site.value_counts().reset_index()\n",
    "    key_value_df = pd.DataFrame() #contains a pair of site-frequency\n",
    "    key_value_df['site'] = freq['index']\n",
    "    key_value_df['count'] = freq['site']\n",
    "    key_value_df.sort_values(by='count', inplace=True, ascending=False) \n",
    "    sites_dict = {} \n",
    "    sites_dict['Unknown'] = 0\n",
    "    for i in np.arange(key_value_df.shape[0]):\n",
    "        if key_value_df.iloc[i,0]!='Unknown':\n",
    "            sites_dict[key_value_df.iloc[i,0]] = i+1\n",
    "    return sites_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>javadl-esd-secure.oracle.com</td>\n",
       "      <td>www.caucho.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>www.caucho.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>master.dl.sourceforge.net</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      site1                          site2  \\\n",
       "session_id                                                                   \n",
       "21669       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                        www.apache.org                 www.apache.org   \n",
       "114021                      www.webtide.com            download.oracle.com   \n",
       "146670                   public.dhe.ibm.com                   jope.ow2.org   \n",
       "\n",
       "                                      site3                          site4  \\\n",
       "session_id                                                                   \n",
       "21669                               Unknown                        Unknown   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                  download.eclipse.org                 www.apache.org   \n",
       "114021                       www.caucho.com            download.oracle.com   \n",
       "146670                  download.oracle.com             public.dhe.ibm.com   \n",
       "\n",
       "                      site5                      site6                site7  \\\n",
       "session_id                                                                    \n",
       "21669               Unknown                    Unknown              Unknown   \n",
       "54843               Unknown                    Unknown              Unknown   \n",
       "77292        www.apache.org            www.webtide.com  download.oracle.com   \n",
       "114021      www.webtide.com             www.apache.org   public.dhe.ibm.com   \n",
       "146670         jope.ow2.org  master.dl.sourceforge.net       www.apache.org   \n",
       "\n",
       "                                   site8           site9              site10  \n",
       "session_id                                                                    \n",
       "21669                            Unknown         Unknown             Unknown  \n",
       "54843                            Unknown         Unknown             Unknown  \n",
       "77292       javadl-esd-secure.oracle.com  www.caucho.com      www.apache.org  \n",
       "114021                   www.webtide.com  www.apache.org      www.apache.org  \n",
       "146670              download.eclipse.org  www.apache.org  public.dhe.ibm.com  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "general_sites = full_sites[sites].apply(lambda ts: ts.map(inverse_dict(site_dict))) #instead of numbers the names of sites\n",
    "general_sites = general_sites.fillna('Unknown')\n",
    "general_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>apache.org</td>\n",
       "      <td>apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>apache.org</td>\n",
       "      <td>apache.org</td>\n",
       "      <td>webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>javadl-esd-secure.oracle.com</td>\n",
       "      <td>caucho.com</td>\n",
       "      <td>apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>caucho.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>webtide.com</td>\n",
       "      <td>apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>webtide.com</td>\n",
       "      <td>apache.org</td>\n",
       "      <td>apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>master.dl.sourceforge.net</td>\n",
       "      <td>apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      site1                          site2  \\\n",
       "session_id                                                                   \n",
       "21669       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                            apache.org                     apache.org   \n",
       "114021                          webtide.com            download.oracle.com   \n",
       "146670                   public.dhe.ibm.com                   jope.ow2.org   \n",
       "\n",
       "                                      site3                          site4  \\\n",
       "session_id                                                                   \n",
       "21669                               Unknown                        Unknown   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                  download.eclipse.org                     apache.org   \n",
       "114021                           caucho.com            download.oracle.com   \n",
       "146670                  download.oracle.com             public.dhe.ibm.com   \n",
       "\n",
       "                   site5                      site6                site7  \\\n",
       "session_id                                                                 \n",
       "21669            Unknown                    Unknown              Unknown   \n",
       "54843            Unknown                    Unknown              Unknown   \n",
       "77292         apache.org                webtide.com  download.oracle.com   \n",
       "114021       webtide.com                 apache.org   public.dhe.ibm.com   \n",
       "146670      jope.ow2.org  master.dl.sourceforge.net           apache.org   \n",
       "\n",
       "                                   site8       site9              site10  \n",
       "session_id                                                                \n",
       "21669                            Unknown     Unknown             Unknown  \n",
       "54843                            Unknown     Unknown             Unknown  \n",
       "77292       javadl-esd-secure.oracle.com  caucho.com          apache.org  \n",
       "114021                       webtide.com  apache.org          apache.org  \n",
       "146670              download.eclipse.org  apache.org  public.dhe.ibm.com  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_sites = general_sites.applymap(lambda site: re.sub(\"^\\S*?\\.*?www\\S*?\\.\", '', site)) \n",
    "general_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48371 47135\n"
     ]
    }
   ],
   "source": [
    "new_site_dict = get_sites_dict_(general_sites)\n",
    "\n",
    "#on a thousand unique sites became less.\n",
    "print(len(list(site_dict.keys())), len(list(new_site_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>474</td>\n",
       "      <td>474</td>\n",
       "      <td>529</td>\n",
       "      <td>474</td>\n",
       "      <td>474</td>\n",
       "      <td>1540</td>\n",
       "      <td>126</td>\n",
       "      <td>66</td>\n",
       "      <td>3272</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>1540</td>\n",
       "      <td>126</td>\n",
       "      <td>3272</td>\n",
       "      <td>126</td>\n",
       "      <td>1540</td>\n",
       "      <td>474</td>\n",
       "      <td>821</td>\n",
       "      <td>1540</td>\n",
       "      <td>474</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>821</td>\n",
       "      <td>2770</td>\n",
       "      <td>126</td>\n",
       "      <td>821</td>\n",
       "      <td>2770</td>\n",
       "      <td>3099</td>\n",
       "      <td>474</td>\n",
       "      <td>529</td>\n",
       "      <td>474</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          30     14      0      0      0      0      0      0      0   \n",
       "54843          30     14     30     14      0      0      0      0      0   \n",
       "77292         474    474    529    474    474   1540    126     66   3272   \n",
       "114021       1540    126   3272    126   1540    474    821   1540    474   \n",
       "146670        821   2770    126    821   2770   3099    474    529    474   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          474  \n",
       "114021         474  \n",
       "146670         821  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[sites] = general_sites.apply(lambda ts: ts.map(new_site_dict)) #new coding\n",
    "\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 21),\n",
       " (82797, 20),\n",
       " (336358, 20),\n",
       " (336358, 10),\n",
       " (253561,),\n",
       " (336358, 20))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape, full_df.shape, full_sites.shape, y_train.shape, full_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will remove outliers in data ie those sessions which lasted over 750 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>529</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>66</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>3272</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>1540</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>3272</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>1540</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>1540</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2770</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2770</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>529</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          30 2013-01-12 08:05:57     14 2013-01-12 08:05:57      0   \n",
       "54843          30 2013-01-12 08:37:23     14 2013-01-12 08:37:23     30   \n",
       "77292         474 2013-01-12 08:50:13    474 2013-01-12 08:50:14    529   \n",
       "114021       1540 2013-01-12 08:50:17    126 2013-01-12 08:50:17   3272   \n",
       "146670        821 2013-01-12 08:50:20   2770 2013-01-12 08:50:20    126   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843      2013-01-12 09:07:07     14 2013-01-12 09:07:09      0   \n",
       "77292      2013-01-12 08:50:15    474 2013-01-12 08:50:15    474   \n",
       "114021     2013-01-12 08:50:18    126 2013-01-12 08:50:18   1540   \n",
       "146670     2013-01-12 08:50:20    821 2013-01-12 08:50:21   2770   \n",
       "\n",
       "                         time5   ...                  time6 site7  \\\n",
       "session_id                       ...                                \n",
       "21669                      NaT   ...                    NaT     0   \n",
       "54843                      NaT   ...                    NaT     0   \n",
       "77292      2013-01-12 08:50:16   ...    2013-01-12 08:50:16   126   \n",
       "114021     2013-01-12 08:50:18   ...    2013-01-12 08:50:18   821   \n",
       "146670     2013-01-12 08:50:21   ...    2013-01-12 08:50:21   474   \n",
       "\n",
       "                         time7 site8               time8 site9  \\\n",
       "session_id                                                       \n",
       "21669                      NaT     0                 NaT     0   \n",
       "54843                      NaT     0                 NaT     0   \n",
       "77292      2013-01-12 08:50:16    66 2013-01-12 08:50:16  3272   \n",
       "114021     2013-01-12 08:50:19  1540 2013-01-12 08:50:19   474   \n",
       "146670     2013-01-12 08:50:21   529 2013-01-12 08:50:22   474   \n",
       "\n",
       "                         time9 site10              time10 duration  \n",
       "session_id                                                          \n",
       "21669                      NaT      0                 NaT      0.0  \n",
       "54843                      NaT      0                 NaT   1786.0  \n",
       "77292      2013-01-12 08:50:17    474 2013-01-12 08:50:17      4.0  \n",
       "114021     2013-01-12 08:50:19    474 2013-01-12 08:50:20      3.0  \n",
       "146670     2013-01-12 08:50:22    821 2013-01-12 08:50:22      2.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a separate dataframe where we will work with timestamps\n",
    "#time_df = pd.DataFrame(index=train_df.index)\n",
    "#time_df['target'] = train_df['target']\n",
    "\n",
    "# Find sessions' starting and ending\n",
    "full_df['min'] = full_df[times].min(axis=1)\n",
    "full_df['max'] = full_df[times].max(axis=1)\n",
    "\n",
    "# Calculate sessions' duration in seconds\n",
    "full_df['duration'] = (full_df['max'] - full_df['min']) / np.timedelta64(1, 's')\n",
    "full_df = full_df.drop(columns=['min','max'])\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = full_df.iloc[0:idx_split]\n",
    "test_df = full_df[idx_split:full_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sita\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df[train_df.duration<750]\n",
    "#test_df = test_df[test_df.duration<750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['target']\n",
    "train_df = train_df.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 21),\n",
       " (82797, 21),\n",
       " (336358, 21),\n",
       " (336358, 10),\n",
       " (253561,),\n",
       " (336358, 21))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape, full_df.shape, full_sites.shape, y_train.shape, full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]\n",
    "full_sites = full_df[sites]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the very basic model, we will use only the visited websites in the session (but we will not take into account timestamp features). The point behind this data selection is: *Alice has her favorite sites, and the more often you see these sites in the session, the higher probability that this is Alice's session, and vice versa.*\n",
    "\n",
    "Let us prepare the data, we will take only features `site1, site2, ... , site10` from the whole dataframe. Keep in mind that the missing values are replaced with zero. Here is how the first rows of the dataframe look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sessions are sequences of website indices, and data in this representation is useless for machine learning method (just think, what happens if we switched all ids of all websites). \n",
    "\n",
    "According to our hypothesis (Alice has favorite websites), we need to transform this dataframe so each website has a corresponding feature (column) and its value is equal to number of this website visits in the session. It can be done in two lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence of indices\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# and the matrix we are looking for \n",
    "# (make sure you understand which of the `csr_matrix` constructors is used here)\n",
    "# a further toy example will help you with it\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336358, 47135)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sites_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, seed=17, ratio = 0.9):\n",
    "    # Split the data into the training and validation sets\n",
    "    idx = int(round(X.shape[0] * ratio))\n",
    "    # Classifier training\n",
    "    lr = LogisticRegression(C=C, random_state=seed, solver='liblinear').fit(X[:idx, :], y[:idx])\n",
    "    # Prediction for validation set\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # Calculate the quality\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184891266804824\n",
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Select the training set from the united dataframe (where we have the answers)\n",
    "X_train = full_sites_sparse[:idx_split, :]\n",
    "\n",
    "# Calculate metric on the validation set\n",
    "print(get_auc_lr_valid(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model demonstrated the quality  of 0.92 on the validation set. Let's take it as the first baseline and starting point. To make a prediction on the test data set **we need to train the model again on the entire training data set** (until this moment, our model used only part of the data for training), which will increase its generalizing ability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>529</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>66</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>3272</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>1540</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>3272</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>1540</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>1540</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2770</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>126</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2770</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>529</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>474</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>821</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          30 2013-01-12 08:05:57     14 2013-01-12 08:05:57      0   \n",
       "54843          30 2013-01-12 08:37:23     14 2013-01-12 08:37:23     30   \n",
       "77292         474 2013-01-12 08:50:13    474 2013-01-12 08:50:14    529   \n",
       "114021       1540 2013-01-12 08:50:17    126 2013-01-12 08:50:17   3272   \n",
       "146670        821 2013-01-12 08:50:20   2770 2013-01-12 08:50:20    126   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843      2013-01-12 09:07:07     14 2013-01-12 09:07:09      0   \n",
       "77292      2013-01-12 08:50:15    474 2013-01-12 08:50:15    474   \n",
       "114021     2013-01-12 08:50:18    126 2013-01-12 08:50:18   1540   \n",
       "146670     2013-01-12 08:50:20    821 2013-01-12 08:50:21   2770   \n",
       "\n",
       "                         time5   ...                  time6 site7  \\\n",
       "session_id                       ...                                \n",
       "21669                      NaT   ...                    NaT     0   \n",
       "54843                      NaT   ...                    NaT     0   \n",
       "77292      2013-01-12 08:50:16   ...    2013-01-12 08:50:16   126   \n",
       "114021     2013-01-12 08:50:18   ...    2013-01-12 08:50:18   821   \n",
       "146670     2013-01-12 08:50:21   ...    2013-01-12 08:50:21   474   \n",
       "\n",
       "                         time7 site8               time8 site9  \\\n",
       "session_id                                                       \n",
       "21669                      NaT     0                 NaT     0   \n",
       "54843                      NaT     0                 NaT     0   \n",
       "77292      2013-01-12 08:50:16    66 2013-01-12 08:50:16  3272   \n",
       "114021     2013-01-12 08:50:19  1540 2013-01-12 08:50:19   474   \n",
       "146670     2013-01-12 08:50:21   529 2013-01-12 08:50:22   474   \n",
       "\n",
       "                         time9 site10              time10 duration  \n",
       "session_id                                                          \n",
       "21669                      NaT      0                 NaT      0.0  \n",
       "54843                      NaT      0                 NaT   1786.0  \n",
       "77292      2013-01-12 08:50:17    474 2013-01-12 08:50:17      4.0  \n",
       "114021     2013-01-12 08:50:19    474 2013-01-12 08:50:20      3.0  \n",
       "146670     2013-01-12 08:50:22    821 2013-01-12 08:50:22      2.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose the training set\n",
    "#full_new_feat['start_hour'] =  pd.DatetimeIndex(full_df['time1']).hour\n",
    "hour = full_df['time1'].apply(lambda ts: ts.hour)\n",
    "full_new_feat = pd.DataFrame()\n",
    "full_new_feat['start_hour'] = hour\n",
    "full_new_feat['morning'] = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "full_new_feat['afternoon'] = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "full_new_feat['evening'] = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "full_new_feat['night'] = ((hour >= 0) & (hour <= 6)).astype('int')\n",
    "full_new_feat['n_unique_sites'] = full_df[sites].nunique(axis=1)\n",
    "full_new_feat['sitescount'] = full_df[sites].gt(0).sum(axis=1)\n",
    "full_new_feat.drop(columns=['start_hour','night'])\n",
    "\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat)\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:], \n",
    "                            tmp_scaled[idx_split:,:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 47142), (82797, 47142))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the whole training data set using optimal regularization parameter\n",
    "C = 1.0\n",
    "lr = LogisticRegression(C=C, random_state=17, solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "# Make a prediction for the test set\n",
    "y_test = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'lr_csr.csv') # gave 0.92352"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us try with count vec of the sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = full_df.iloc[0:idx_split]\n",
    "test_df = full_df[idx_split:full_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 21), (82797, 21), (253561,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[sites].fillna(0).astype('int').to_csv('train_sessions_text.txt', \n",
    "                                               sep=' ', \n",
    "                       index=None, header=None)\n",
    "test_df[sites].fillna(0).astype('int').to_csv('test_sessions_text.txt', \n",
    "                                              sep=' ', \n",
    "                       index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 75000), (82797, 75000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=75000)\n",
    "with open('train_sessions_text.txt') as inp_train_file:\n",
    "    X_train_cv = cv.fit_transform(inp_train_file)\n",
    "with open('test_sessions_text.txt') as inp_test_file:\n",
    "    X_test_cv = cv.transform(inp_test_file)\n",
    "X_train_cv.shape, X_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat)\n",
    "X_train_new = hstack([X_train_cv, tmp_scaled[:idx_split,:]])\n",
    "X_test_new = hstack([X_test_cv, tmp_scaled[idx_split:,:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the whole training data set using optimal regularization parameter\n",
    "C = 1.0 \n",
    "\n",
    "lr = LogisticRegression(C=C, random_state=17, solver='liblinear').fit(X_train_new, y_train)\n",
    "\n",
    "# Make a prediction for the test set\n",
    "y_test = lr.predict_proba(X_test_new)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'lr_countvec.csv') # 0.92488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logit = LogisticRegression(random_state=17, class_weight='balanced')\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "c_values = np.logspace(-2, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logit_cv = GridSearchCV(estimator=logit, param_grid={'C': c_values}, scoring='roc_auc', cv=skf, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 22.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.0774263682681127, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=17,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " {'C': 0.0774263682681127},\n",
       " 0.9753470161078026)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_cv.fit(X_train_new, y_train)\n",
    "logit_cv.score\n",
    "logit_cv.best_estimator_, logit_cv.best_params_, logit_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 21.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.21544346900318834, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=17,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " {'C': 0.21544346900318834},\n",
       " 0.9788270102202453)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with the csr data\n",
    "logit_cv2 = GridSearchCV(estimator=logit, param_grid={'C': c_values}, scoring='roc_auc', cv=skf, verbose=1)\n",
    "logit_cv2.fit(X_train, y_train)\n",
    "logit_cv2.score\n",
    "logit_cv2.best_estimator_, logit_cv2.best_params_, logit_cv2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction for the test set\n",
    "y_test = logit_cv.predict_proba(X_test_new)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'lr_cv_countvec.csv') #score 0.90856 (sparse), 0.92765 (count vec), 0.92518 (countvec 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-51a85a2a3b01>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-51a85a2a3b01>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ************\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_part, X_valid, y_train_part, y_valid = \\\n",
    "    train_test_split(X_train_new, y_train, \n",
    "                     test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm5 = LGBMClassifier(random_state=17, n_estimators=1000, colsample_bytree=0.66,\n",
    "                       max_depth=-1, num_leaves=5, reg_alpha=1.2, subsample=0.75,\n",
    "                       reg_lambda=1, learning_rate=0.5)\n",
    "lgbm5.fit(X_train_part, y_train_part)\n",
    "lgbm_valid_pred = lgbm5.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_valid, lgbm_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lgbm5.fit(X_train, y_train)\n",
    "y_test = lgbm5.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'lgbm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score was 0.78186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'num_leaves': [7, 15, 31, 63, 127, 255],\n",
    "              'max_depth': [3, 4, 5, 6]}\n",
    "grid_search = GridSearchCV(estimator=lgbm5, param_grid=parameters, \n",
    "                           verbose=1, scoring='roc_auc',\n",
    "                           n_jobs=4, cv=5)\n",
    "grid_search = grid_search.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm6 = LGBMClassifier(random_state=17, n_estimators=1000, colsample_bytree=0.66,\n",
    "                       max_depth=6, num_leaves=15, reg_alpha=1.2, subsample=0.75,\n",
    "                       reg_lambda=1, learning_rate=0.5)\n",
    "lgbm6.fit(X_train_part, y_train_part)\n",
    "lgbm_valid_pred = lgbm6.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_valid, lgbm_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm6.fit(X_train, y_train)\n",
    "y_test = lgbm6.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'lgbm6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score = 0.70012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(seed=17)\n",
    "xgb.fit(X_train_part, y_train_part)\n",
    "xgb_valid_pred = xgb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, xgb_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)\n",
    "y_test = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'xgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score = 0.87814, let us fine tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_part, X_valid, y_train_part, y_valid = \\\n",
    "    train_test_split(X_train_new, y_train, \n",
    "                     test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(seed=17, n_estimators=500)\n",
    "xgb.fit(X_train_part, y_train_part)\n",
    "xgb_valid_pred = xgb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, xgb_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train_new, y_train)\n",
    "y_test = xgb.predict_proba(X_test_new)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'xgb2.csv') # 0.90541"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score = 0.90371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'num_leaves': [7, 15, 31, 63, 127, 255],\n",
    "              'max_depth': [3, 4, 5, 6]}\n",
    "grid_search2 = GridSearchCV(estimator=xgb, param_grid=parameters, \n",
    "                           verbose=1, scoring='roc_auc',\n",
    "                           n_jobs=4, cv=5)\n",
    "grid_search2 = grid_search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2.best_params_, grid_search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(seed=17, n_estimators=500, max_depth=6, num_leaves=15)\n",
    "xgb3.fit(X_train_part, y_train_part)\n",
    "xgb_valid_pred = xgb3.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, xgb_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3.fit(X_train, y_train)\n",
    "y_test = xgb3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'xgb3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score = 0.90039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv('xgb2.csv')\n",
    "p2 = pd.read_csv('countvec_lr_cv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = 0.4*p1['target'] + 0.6*p2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(p3, name='target').to_csv('p3.csv', index_label='session_id', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score = 0.92685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = 0.2*p1['target'] + 0.8*p2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(p4, name='target').to_csv('p8.csv', index_label='session_id', header=True) #lr_cv countvec with xgb2 stacked 0.93419"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score = 0.92865\n",
    "\n",
    "## New score = 0.92444\n",
    "\n",
    "## After adding all features : 0.92548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv('xgb2.csv')\n",
    "p2 = pd.read_csv('lgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = 0.6*p1['target'] + 0.4*p2['target']\n",
    "p5.index += 1\n",
    "pd.Series(p5, name='target').to_csv('p5.csv', index_label='session_id', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score = 0.90100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
